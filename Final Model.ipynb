{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neccesary modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_rf = np.load(\"data/backgroundRF_resampled.npy\")\n",
    "drone_rf = np.load(\"data/droneRF_resampled.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_imgs = np.load(\"data/images_background.npy\", allow_pickle=True)\n",
    "drone_imgs = np.load(\"data/images_drone.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_imgs /= 255\n",
    "background_imgs /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(drone_imgs)\n",
    "random.shuffle(background_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/ test split and data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/NewUsersDir/mohammed/nkalathi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "images_data = np.append(background_imgs[0:len(background_rf)], \n",
    "                   drone_imgs[0:len(drone_rf)], axis=0)\n",
    "images_resized = []\n",
    "for i, img in enumerate(images_data):\n",
    "    images_resized.append(cv2.resize(img, (256, 256), \n",
    "                                interpolation = cv2.INTER_AREA))\n",
    "    images_resized[i] = np.expand_dims(images_resized[i], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_resized = np.array(images_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(images_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([0 for i in enumerate(background_rf)] + [1 for i in enumerate(drone_rf)])\n",
    "X = np.append(background_rf,drone_rf,axis=0)\n",
    "Y = Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(rf_data,images):\n",
    "    low = []\n",
    "    high = []\n",
    "    images = images\n",
    "    for i, rf in enumerate(rf_data):\n",
    "        low.append(rf[0].astype(np.float16).flatten())\n",
    "        high.append(rf[1].astype(np.float16).flatten())\n",
    "    low = np.array(low)\n",
    "    high = np.array(high)\n",
    "    images = np.array(images)\n",
    "    return [low, high, images]\n",
    "X = format_data(X, images_resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_data(x_data):\n",
    "    data = []\n",
    "    for i in range(len(x_data[0])):\n",
    "        data.append((x_data[0][i], x_data[1][i], x_data[2][i]))\n",
    "    return data\n",
    "def unjoin_data(x_data):\n",
    "    low = []\n",
    "    high = []\n",
    "    imags = []\n",
    "    for x in x_data:\n",
    "        low.append(x[0])\n",
    "        high.append(x[1])\n",
    "        imags.append(x[2])\n",
    "    low = np.array(low)\n",
    "    high = np.array(high)\n",
    "    imags = np.array(imags)\n",
    "    return [low, high, imags] \n",
    "X = join_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = unjoin_data(x_test)\n",
    "x_train = unjoin_data(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 4882)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv2d_input (InputLayer)       [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 254, 254, 32) 320         conv2d_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 254, 254, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 252, 252, 32) 9248        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 252, 252, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 126, 126, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 126, 126, 32) 0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 124, 124, 64) 18496       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 124, 124, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 124, 124, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 122, 122, 128 73856       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 122, 122, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 61, 61, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 61, 61, 128)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 476288)       0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          243859968   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 4882)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4882)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 512)          2048        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          488300      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          488300      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50)           5050        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 50)           5050        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          65664       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 228)          0           dense_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           2290        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            11          dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 245,019,625\n",
      "Trainable params: 245,018,089\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, concatenate\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2,3\"\n",
    "\n",
    "img_shape = (256,256,1)\n",
    "# define three sets of inputs\n",
    "low_rf  = Input(shape=(x_train[0].shape[1],))\n",
    "high_rf = Input(shape=(x_train[1].shape[1],))\n",
    "\n",
    "# the first branch operates on the first input\n",
    "x1 = Dense(100 , activation=\"relu\")(low_rf)\n",
    "x1 = Dense(50, activation=\"relu\")(x1)\n",
    "x1 = Model(inputs=low_rf, outputs=x1)\n",
    "\n",
    "# the second branch operates on the second input\n",
    "x2 = Dense(100 , activation=\"relu\")(high_rf)\n",
    "x2 = Dense(50, activation=\"relu\")(x2)\n",
    "x2 = Model(inputs=high_rf, outputs=x2)\n",
    "\n",
    "# third branch for images \n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=img_shape))\n",
    "cnn.add(BatchNormalization())\n",
    "\n",
    "cnn.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "\n",
    "cnn.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Dropout(0.25))\n",
    "\n",
    "cnn.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(512, activation='relu'))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Dropout(0.5))\n",
    "\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "\n",
    "# combine the output of the two branches\n",
    "combined = concatenate([x1.output, x2.output, cnn.output])\n",
    "\n",
    "# apply a FC layer and then a regression prediction on the\n",
    "# combined outputs\n",
    "z = Dense(10, activation=\"relu\")(combined)\n",
    "z = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(inputs=[x1.input, x2.input, cnn.input], outputs=z)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='adam' , loss = \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate model picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56 samples, validate on 24 samples\n",
      "Epoch 1/3\n",
      "56/56 [==============================] - 8s 145ms/sample - loss: 0.6085 - accuracy: 0.6607 - val_loss: 0.4606 - val_accuracy: 0.8333\n",
      "Epoch 2/3\n",
      "56/56 [==============================] - 4s 80ms/sample - loss: 0.1540 - accuracy: 0.9821 - val_loss: 0.4694 - val_accuracy: 0.8333\n",
      "Epoch 3/3\n",
      "56/56 [==============================] - 4s 80ms/sample - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.7917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5ae01dc110>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size =1\n",
    "epochs = 3\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5120420455932617\n",
      "Test accuracy: 0.7916667\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24265236]\n",
      " [0.20384699]\n",
      " [0.01700017]\n",
      " [0.28676224]\n",
      " [0.00672624]\n",
      " [0.25819   ]\n",
      " [0.25713205]\n",
      " [0.23931003]\n",
      " [0.01865175]\n",
      " [0.0350244 ]\n",
      " [0.32323837]\n",
      " [0.0475032 ]\n",
      " [0.6486509 ]\n",
      " [0.22804645]\n",
      " [0.9581479 ]\n",
      " [0.02113104]\n",
      " [0.98134875]\n",
      " [0.25115043]\n",
      " [0.528554  ]\n",
      " [0.07326195]\n",
      " [0.33905202]\n",
      " [0.9906651 ]\n",
      " [0.17063457]\n",
      " [0.42885685]]\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.5\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# predictions = (predictions > THRESHOLD)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0]\n",
      " [ 5  5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, (predictions> THRESHOLD))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02113104 0.0350244  0.0475032  0.07326195 0.17063457 0.20384699\n",
      " 0.22804645 0.23931003 0.24265236 0.25115043 0.25713205 0.25819\n",
      " 0.28676224 0.32323837 0.33905202 0.42885685 0.528554   0.6486509\n",
      " 0.9581479  0.98134875 0.9906651 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, predictions)\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, predictions)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
